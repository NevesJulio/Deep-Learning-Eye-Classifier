{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77ce1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155d6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"        # pasta com as duas classes\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "DEVICE = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização padrão ImageNet\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Transform padrão para ResNet50 (sem data augmentation)\n",
    "IMAGENET_transform = transforms.Compose([\n",
    "    transforms.Resize(256),           # aumenta a menor dimensão para 256\n",
    "    transforms.CenterCrop(224),       # corta para 224x224\n",
    "    transforms.ToTensor(),            # converte PIL->Tensor e escala [0,1]\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb1d5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo a classe do dataset\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform or default_transform  # se não passar transform, usa padrão\n",
    "        self.samples = []  # [(img_path, label_idx), ...]\n",
    "        self.class_to_idx = {}  # {\"classe\": idx}\n",
    "\n",
    "        # Cria lista de imagens + label\n",
    "        for i, class_dir in enumerate(sorted(p for p in self.root_dir.iterdir() if p.is_dir())):\n",
    "            self.class_to_idx[class_dir.name] = i\n",
    "            for img_path in class_dir.glob('*'):\n",
    "                self.samples.append((img_path, i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"ImageDataset with {len(self)} samples from {len(self.class_to_idx)} classes.\"\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "\n",
    "        # Abre a imagem de forma segura\n",
    "        with open(img_path, 'rb') as f:\n",
    "            img = Image.open(f).convert('RGB')  # garante 3 canais\n",
    "\n",
    "        # Aplica transformações (pré-processamento/resnet normalization)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "491d797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo dataset em treino e validação\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "dataset = ImageDataset(\"data\\DataSet\")  # pasta com as 2 classes\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size   = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d493a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24710cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo ResNet50\n",
    "num_classes = len(dataset.class_to_idx)\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)  # pretreinada\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)                  # ajusta a última camada para 2 classes\n",
    "model = model.to(\"cuda\") #Escolha de onde rodar o modelo\n",
    "\n",
    "#Escolha do normalizador, otimizador e LR\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a802682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.1388 Acc: 0.9418 | Val Loss: 0.0566 Acc: 0.9862\n",
      "Epoch 2/10 | Train Loss: 0.0298 Acc: 0.9891 | Val Loss: 0.0593 Acc: 0.9803\n",
      "Epoch 3/10 | Train Loss: 0.0160 Acc: 0.9965 | Val Loss: 0.0422 Acc: 0.9822\n",
      "Epoch 4/10 | Train Loss: 0.0038 Acc: 1.0000 | Val Loss: 0.0454 Acc: 0.9822\n",
      "Epoch 5/10 | Train Loss: 0.0035 Acc: 1.0000 | Val Loss: 0.0447 Acc: 0.9822\n",
      "Epoch 6/10 | Train Loss: 0.0064 Acc: 0.9985 | Val Loss: 0.0563 Acc: 0.9842\n",
      "Epoch 7/10 | Train Loss: 0.0325 Acc: 0.9896 | Val Loss: 0.0604 Acc: 0.9862\n",
      "Epoch 8/10 | Train Loss: 0.0254 Acc: 0.9921 | Val Loss: 0.0437 Acc: 0.9822\n",
      "Epoch 9/10 | Train Loss: 0.0127 Acc: 0.9965 | Val Loss: 0.0695 Acc: 0.9822\n",
      "Epoch 10/10 | Train Loss: 0.0032 Acc: 1.0000 | Val Loss: 0.0504 Acc: 0.9862\n",
      "Modelo salvo em resnet50_finetuned.pth\n"
     ]
    }
   ],
   "source": [
    "#treino e validação\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss /= total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # ---- Validação ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 7️⃣ Salvar modelo\n",
    "# ------------------------------\n",
    "torch.save(model.state_dict(), \"resnet50_finetuned.pth\")\n",
    "print(\"Modelo salvo em resnet50_finetuned.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Config import train_and_validate\n",
    "\n",
    "# Definir modelo, dataloaders, criterion, optimizer, etc.\n",
    "MODEL_NAME = \"resnet50\" # Nome do modelo\n",
    "SAVE_PATH = f\"{MODEL_NAME}_finetuned.pth\"\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    epochs=EPOCHS,\n",
    "    save_path=SAVE_PATH\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
