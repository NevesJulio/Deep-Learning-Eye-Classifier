{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77ce1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155d6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"        # pasta com as duas classes\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "DEVICE = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837f697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definição de parametros da RESNET50\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # tamanho que o ViT espera\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491d797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo dataset em treino e validação\n",
    "from Config import ImageDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "dataset = ImageDataset(\"data\\DataSet\", default_transform)  # pasta com as 2 classes\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size   = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d493a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24710cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to C:\\Users\\Julio/.cache\\torch\\hub\\checkpoints\\vit_b_16-c867db91.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Modelo Vision Transformer (ViT-B/16)\n",
    "num_classes = len(dataset.class_to_idx)\n",
    "model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)  # pré-treinada\n",
    "model.heads.head = nn.Linear(model.heads.head.in_features, num_classes) # ajusta a última camada\n",
    "model = model.to(\"cuda\")  # GPU\n",
    "\n",
    "# Critério de perda e otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a802682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.2210 Acc: 0.9038 | Val Loss: 0.0879 Acc: 0.9684\n",
      "Epoch 2/10 | Train Loss: 0.1024 Acc: 0.9605 | Val Loss: 0.0721 Acc: 0.9724\n",
      "Epoch 3/10 | Train Loss: 0.0455 Acc: 0.9798 | Val Loss: 0.1234 Acc: 0.9625\n",
      "Epoch 4/10 | Train Loss: 0.0413 Acc: 0.9872 | Val Loss: 0.0596 Acc: 0.9704\n",
      "Epoch 5/10 | Train Loss: 0.0449 Acc: 0.9812 | Val Loss: 0.0595 Acc: 0.9763\n",
      "Epoch 6/10 | Train Loss: 0.0181 Acc: 0.9931 | Val Loss: 0.0429 Acc: 0.9803\n",
      "Epoch 7/10 | Train Loss: 0.0498 Acc: 0.9803 | Val Loss: 0.0667 Acc: 0.9684\n",
      "Epoch 8/10 | Train Loss: 0.0403 Acc: 0.9837 | Val Loss: 0.0716 Acc: 0.9724\n",
      "Epoch 9/10 | Train Loss: 0.0276 Acc: 0.9891 | Val Loss: 0.0922 Acc: 0.9744\n",
      "Epoch 10/10 | Train Loss: 0.0392 Acc: 0.9877 | Val Loss: 0.0749 Acc: 0.9704\n",
      "Modelo salvo em VisualTransformer_finetuned.pth\n"
     ]
    }
   ],
   "source": [
    "from Config import train_and_validate\n",
    "\n",
    "# Definir modelo, dataloaders, criterion, optimizer, etc.\n",
    "MODEL_NAME = \"VisualTransformer\" # Nome do modelo\n",
    "SAVE_PATH = f\"{MODEL_NAME}_finetuned.pth\"\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    epochs=EPOCHS,\n",
    "    save_path=SAVE_PATH\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
