{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77ce1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155d6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"        # pasta com as duas classes\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "DEVICE = \"cuda\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837f697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização padrão ImageNet\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Transform padrão para ResNet50 (sem data augmentation)\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.Resize(256),           # aumenta a menor dimensão para 256\n",
    "    transforms.CenterCrop(224),       # corta para 224x224\n",
    "    transforms.ToTensor(),            # converte PIL->Tensor e escala [0,1]\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb1d5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo a classe do dataset\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform or default_transform  # se não passar transform, usa padrão\n",
    "        self.samples = []  # [(img_path, label_idx), ...]\n",
    "        self.class_to_idx = {}  # {\"classe\": idx}\n",
    "\n",
    "        # Cria lista de imagens + label\n",
    "        for i, class_dir in enumerate(sorted(p for p in self.root_dir.iterdir() if p.is_dir())):\n",
    "            self.class_to_idx[class_dir.name] = i\n",
    "            for img_path in class_dir.glob('*'):\n",
    "                self.samples.append((img_path, i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"ImageDataset with {len(self)} samples from {len(self.class_to_idx)} classes.\"\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "\n",
    "        # Abre a imagem de forma segura\n",
    "        with open(img_path, 'rb') as f:\n",
    "            img = Image.open(f).convert('RGB')  # garante 3 canais\n",
    "\n",
    "        # Aplica transformações (pré-processamento/resnet normalization)\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491d797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo dataset em treino e validação\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "dataset = ImageDataset(\"data\\DataSet\")  # pasta com as 2 classes\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size   = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d493a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24710cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\Julio/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Modelo DenseNet121\n",
    "num_classes = len(dataset.class_to_idx)\n",
    "model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)  # pré-treinada\n",
    "model.classifier = nn.Linear(model.classifier.in_features, num_classes)       # ajusta a última camada\n",
    "model = model.to(\"cuda\")  # GPU\n",
    "\n",
    "# Critério de perda e otimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a802682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 0.1683 Acc: 0.9348 | Val Loss: 0.0660 Acc: 0.9783\n",
      "Epoch 2/10 | Train Loss: 0.0441 Acc: 0.9882 | Val Loss: 0.0510 Acc: 0.9803\n",
      "Epoch 3/10 | Train Loss: 0.0109 Acc: 0.9995 | Val Loss: 0.0302 Acc: 0.9941\n",
      "Epoch 4/10 | Train Loss: 0.0045 Acc: 1.0000 | Val Loss: 0.0308 Acc: 0.9882\n",
      "Epoch 5/10 | Train Loss: 0.0049 Acc: 0.9990 | Val Loss: 0.0368 Acc: 0.9882\n",
      "Epoch 6/10 | Train Loss: 0.0096 Acc: 0.9970 | Val Loss: 0.0393 Acc: 0.9901\n",
      "Epoch 7/10 | Train Loss: 0.0303 Acc: 0.9906 | Val Loss: 0.0871 Acc: 0.9724\n",
      "Epoch 8/10 | Train Loss: 0.0193 Acc: 0.9951 | Val Loss: 0.0800 Acc: 0.9724\n",
      "Epoch 9/10 | Train Loss: 0.0152 Acc: 0.9951 | Val Loss: 0.0389 Acc: 0.9862\n",
      "Epoch 10/10 | Train Loss: 0.0107 Acc: 0.9961 | Val Loss: 0.0270 Acc: 0.9862\n",
      "Modelo salvo em densenet121_finetuned.pth\n"
     ]
    }
   ],
   "source": [
    "#treino e validação\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss /= total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # ---- Validação ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss /= total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "#Salvar modelo\n",
    "\n",
    "MODEL_NAME = \"densenet121\" # Nome do modelo\n",
    "SAVE_PATH = f\"{MODEL_NAME}_finetuned.pth\"\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "print(f\"Modelo salvo em {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Config import train_and_validate\n",
    "\n",
    "# Definir modelo, dataloaders, criterion, optimizer, etc.\n",
    "MODEL_NAME = \"densenet121\" # Nome do modelo\n",
    "SAVE_PATH = f\"{MODEL_NAME}_finetuned.pth\"\n",
    "\n",
    "train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    epochs=EPOCHS,\n",
    "    save_path=SAVE_PATH\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
